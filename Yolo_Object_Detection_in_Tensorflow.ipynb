{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqW0efzXELS9jSPHXj0V8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iMan0405/Portfolio_DT_vs_AI/blob/main/Yolo_Object_Detection_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kutubxonalarni yuklash"
      ],
      "metadata": {
        "id": "cV2jqn6Y9YKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zhpq3a379PRV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "    return tf.layers.batch_normalization(\n",
        "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
        "        scale=True, training=training)\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "    pad_total = kernel_size - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                        [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end]])\n",
        "    else:\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end], [0, 0]])\n",
        "    return padded_inputs\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    if strides > 1:\n",
        "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "    return tf.layers.conv2d(\n",
        "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
        "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
        "        use_bias=False, data_format=data_format)"
      ],
      "metadata": {
        "id": "J575DIFM_GY0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53_residual_block(inputs, filters, training, data_format,\n",
        "                             strides=1):\n",
        "    shortcut = inputs\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs += shortcut\n",
        "\n",
        "    return inputs\n",
        "\n",
        "def darknet53(inputs, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
        "                                      data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(2):\n",
        "        inputs = darknet53_residual_block(inputs, filters=64,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=128,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route1 = inputs\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=256,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route2 = inputs\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(4):\n",
        "        inputs = darknet53_residual_block(inputs, filters=512,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    return route1, route2, inputs"
      ],
      "metadata": {
        "id": "TAQgH3_DNwpT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_convolution_block(inputs, filters, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    route = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    return route, inputs"
      ],
      "metadata": {
        "id": "RlS1qgFbAR8t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1eZRUm_Bj2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}