{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjYkoevV/mm+oIfAJM/nhs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iMan0405/Portfolio_DT_vs_AI/blob/main/Yolo_Object_Detection_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kutubxonalarni yuklash"
      ],
      "metadata": {
        "id": "cV2jqn6Y9YKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zhpq3a379PRV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "    return tf.layers.batch_normalization(\n",
        "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
        "        scale=True, training=training)\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "    pad_total = kernel_size - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                        [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end]])\n",
        "    else:\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end], [0, 0]])\n",
        "    return padded_inputs\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    if strides > 1:\n",
        "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "    return tf.layers.conv2d(\n",
        "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
        "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
        "        use_bias=False, data_format=data_format)"
      ],
      "metadata": {
        "id": "J575DIFM_GY0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53_residual_block(inputs, filters, training, data_format,\n",
        "                             strides=1):\n",
        "    shortcut = inputs\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs += shortcut\n",
        "\n",
        "    return inputs\n",
        "\n",
        "def darknet53(inputs, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
        "                                      data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(2):\n",
        "        inputs = darknet53_residual_block(inputs, filters=64,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=128,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route1 = inputs\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=256,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route2 = inputs\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(4):\n",
        "        inputs = darknet53_residual_block(inputs, filters=512,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    return route1, route2, inputs"
      ],
      "metadata": {
        "id": "TAQgH3_DNwpT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_convolution_block(inputs, filters, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    route = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    return route, inputs"
      ],
      "metadata": {
        "id": "RlS1qgFbAR8t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
        "    n_anchors = len(anchors)\n",
        "\n",
        "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
        "                              kernel_size=1, strides=1, use_bias=True,\n",
        "                              data_format=data_format)\n",
        "\n",
        "    shape = inputs.get_shape().as_list()\n",
        "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
        "                                 5 + n_classes])\n",
        "\n",
        "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
        "\n",
        "    box_centers, box_shapes, confidence, classes = \\\n",
        "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
        "\n",
        "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
        "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
        "    x_offset, y_offset = tf.meshgrid(x, y)\n",
        "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
        "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
        "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
        "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
        "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
        "    box_centers = tf.nn.sigmoid(box_centers)\n",
        "    box_centers = (box_centers + x_y_offset) * strides\n",
        "\n",
        "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
        "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
        "\n",
        "    confidence = tf.nn.sigmoid(confidence)\n",
        "\n",
        "    classes = tf.nn.sigmoid(classes)\n",
        "\n",
        "    inputs = tf.concat([box_centers, box_shapes,\n",
        "                        confidence, classes], axis=1)\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "i1eZRUm_Bj2t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(inputs, out_shape, data_format):\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "        new_height = out_shape[3]\n",
        "        new_width = out_shape[2]\n",
        "    else:\n",
        "        new_height = out_shape[2]\n",
        "        new_width = out_shape[1]\n",
        "\n",
        "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "ZlTD-pNFvJAh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_boxes(inputs):\n",
        "    center_x, center_y, width, height, confidence, classes = \\\n",
        "        tf.split(inputs, [1, 1, 1, 1, 1, -1], exis=1)\n",
        "\n",
        "    top_left_x = center_x - width / 2\n",
        "    top_left_y = center_y - height / 2\n",
        "    bottom_right_x = center_x + width / 2\n",
        "    bottom_right_y = center_y + height / 2\n",
        "\n",
        "    boxes = tf.concat([top_left_x, top_left_y,\n",
        "                       bottom_right_x, bottom_right_y,\n",
        "                       confidence, classes], axis=1)\n",
        "\n",
        "    return boxes\n",
        "\n",
        "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold,\n",
        "                        confidence_threshold):\n",
        "    batch = tf.unstack(inputs)\n",
        "    boxes_dicts = []\n",
        "    for boxes in batch:\n",
        "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
        "        classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
        "        classes = tf.expand_dims(tf.to_float(classes), axis=-1)\n",
        "        boxes = tf.concat([boxes[:, :5], classes], axis=-1)\n",
        "\n",
        "        boxes_dict = dict()\n",
        "        for cls in range(n_classes):\n",
        "            mask = tf.equal(boxes[:, 5], cls)\n",
        "            mask_shape = mask.get_shape()\n",
        "            if mask_shape.ndims != 0:\n",
        "                class_boxes = tf.boolean_mask(boxes, mask)\n",
        "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,\n",
        "                                                              [4, 1, -1],\n",
        "                                                              axis=-1)\n",
        "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
        "                indices = tf.image.non_max_suppression(boxes_coords,\n",
        "                                                       boxes_conf_scores,\n",
        "                                                       max_output_size,\n",
        "                                                       iou_threshold)\n",
        "                class_boxes = tf.gather(class_boxes, indices)\n",
        "                boxes_dict[cls] = class_boxes[:, :5]\n",
        "        boxes_dicts.append(boxes_dict)\n",
        "    return boxes_dicts"
      ],
      "metadata": {
        "id": "jt1b7M6A08TM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8CnpW7n-3ZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}